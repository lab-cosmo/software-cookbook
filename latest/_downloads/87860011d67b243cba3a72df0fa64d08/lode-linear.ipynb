{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# LODE Tutorial\n\n:Authors: Philip Loche [@PicoCentauri](https://github.com/PicoCentauri/),\n          Kevin Huguenin-Dumittan [@kvhuguenin](https://github.com/kvhuguenin)\n\nThis tutorial explains how Long range equivariant descriptors can be constructed using\nrascaline and the resulting descriptors be used to construct a linear model with\nequisolve\n\nFirst, import all the necessary packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import ase.io\nimport matplotlib.pyplot as plt\nimport metatensor\nimport numpy as np\nfrom equisolve.numpy.models.linear_model import Ridge\nfrom equisolve.utils.convert import ase_to_tensormap\nfrom rascaline import AtomicComposition, LodeSphericalExpansion, SphericalExpansion\nfrom rascaline.utils import PowerSpectrum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 0: Prepare Data Set\n\n### Get structures\n\nWe take a small subset of the dimer dataset from [A. Grisafi et al.,\n2021](https://pubs.rsc.org/en/content/articlelanding/2021/sc/d0sc04934d)\nfor which we additionally calculated the forces. Each structure in the\ndataset contains two small organic molecules which are extended along a\ncertain direction in the subsequent structures.\n\nFor speeding up the calculations we already selected the first 130\n:download:`structures <charge-charge.xyz>` of the charge-charge molecule\npairs.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "frames = ase.io.read(\"charge-charge.xyz\", \":\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Convert target properties to metatensor format\n\nIf we want to train models using the\n[equisolve](https://github.com/lab-cosmo/equisolve) package, we need to\nconvert the target properties (in this case, the energies and forces)\ninto the appropriate format #justequistorethings\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "y = ase_to_tensormap(frames, energy=\"energy\", forces=\"forces\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Compute short-range and LODE features\n\nDefine hypers and get the expansion coefficients $\\langle anlm | \\rho_i \\rangle$\nand $\\langle anlm | V_i \\rangle$\n\nThe short-range and long-range descriptors have very similar hyperparameters. We\nhighlight the differences below.\n\nWe first define the hyperparameters for the short-range (SR) part. These will be used\nto create SOAP features.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "SR_HYPERS = {\n    \"cutoff\": 3.0,\n    \"max_radial\": 6,\n    \"max_angular\": 2,\n    \"atomic_gaussian_width\": 0.3,\n    \"center_atom_weight\": 1.0,\n    \"radial_basis\": {\"Gto\": {}},\n    \"cutoff_function\": {\"ShiftedCosine\": {\"width\": 0.5}},\n}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And next the hyperparaters for the LODE / long-range (LR) part\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "LR_HYPERS = {\n    # Cutoff on which to project potential density\n    \"cutoff\": 3.0,\n    # keep max_radial slightly smaller than for SR part\n    \"max_radial\": 3,\n    # max_angular should be <= 4, more precisely, max_angular + potential_exponent < 10\n    \"max_angular\": 2,\n    # keep at >=1, WARNING: CUBIC SCALING, do not use values <0.5\n    \"atomic_gaussian_width\": 3.0,\n    \"center_atom_weight\": 1.0,\n    \"radial_basis\": {\"Gto\": {}},\n    # the exponent p that determines the 1/r^p potential\n    \"potential_exponent\": 1,\n}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We then use the above defined hyperparaters to define the per atom short range (sr)\nand long range (sr) descriptors.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "calculator_sr = SphericalExpansion(**SR_HYPERS)\ncalculator_lr = LodeSphericalExpansion(**LR_HYPERS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that LODE requires periodic systems. Therefore, if the data set does not come\nwith periodic boundary conditions by default you can not use the data set and you will\nface an error if you try to compute the features.\n\nAs you notices the calculation of the long range features takes significant more time\ncompared to the sr features.\n\nTaking a look at the output we find that the resulting\n:py:class:`metatensor.TensorMap` are quite similar in their structure. The short range\n:py:class:`metatensor.TensorMap` contains more blocks due to the higher\n``max_angular`` paramater we choosed above.\n\n### Generate the rotational invariants (power spectra)\n\nRotationally invariant features can be obtained by taking two of the calculators that\nwere defines above.\n\nFor the short-range part, we use the SOAP vector which is obtained by computing the\ninvariant combinations of the form $\\rho \\otimes \\rho$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ps_calculator_sr = PowerSpectrum(calculator_sr, calculator_sr)\nps_sr = ps_calculator_sr.compute(frames, gradients=[\"positions\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We calculate gradients with respect to pistions by providing the\n``gradients=[\"positions\"]`` option to the\n:py:meth:`rascaline.calculators.CalculatorBase.compute()` method.\n\nFor the long-range part, we combine the long-range descriptor $V$ with one a\nshort-range density $\\rho$ to get $\\rho \\otimes V$ features.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ps_calculator_lr = PowerSpectrum(calculator_sr, calculator_lr)\nps_lr = ps_calculator_lr.compute(systems=frames, gradients=[\"positions\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Building a Simple Linear SR + LR Model with energy baselining\n\n### Preprocessing (model dependent)\n\nFor our current model, we do not wish to treat the individual center and\nneighbor species separately. Thus, we move the ``\"species_center\"`` key\ninto the ``sample`` direction, over which we will later sum over.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ps_sr = ps_sr.keys_to_samples(\"species_center\")\nps_lr = ps_lr.keys_to_samples(\"species_center\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For linear models only: Sum features up over atoms (``samples``) in the same\nstructure.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sample_names_to_sum = [\"center\", \"species_center\"]\n\nps_sr = metatensor.sum_over_samples(ps_sr, sample_names=sample_names_to_sum)\nps_lr = metatensor.sum_over_samples(ps_lr, sample_names=sample_names_to_sum)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initialize tensormaps for energy baselining\n\nWe add a simple extra descriptor :py:class:`rascaline.AtomicComposition` that stores\nhow many atoms of each chemical species are contained in the structures. This is used\nfor energy baselining.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "calculator_co = AtomicComposition(per_structure=False)\ndescriptor_co = calculator_co.compute(frames, gradients=[\"positions\"])\n\nco = descriptor_co.keys_to_properties([\"species_center\"])\nco = metatensor.sum_over_samples(co, sample_names=[\"center\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The :py:class:`rascaline.AtomicComposition` calculator also allows to directly perform\nthe the sum over center atoms by using the following lines.\n\n.. code:: python\n\n   descriptor_co = AtomicComposition(per_structure=True).compute(**compute_args)\n   co = descriptor_co.keys_to_properties([\"species_center\"])\n\n### Stack all the features together for linear model\n\nA linear model on SR + LR features can be thought of as a linear model\nbuilt on a feature vector that is simply the concatenation of the SR and\nLR features.\n\nFurthermore, energy baselining can be performed by concatenating the information about\nchemical species as well. There is an metatensor function called\n:py:func:`metatensor.join()` for this purpose. Formally, we can write for the SR\nmodel.\n\nX_sr: $1 \\oplus \\left(\\rho \\otimes \\rho\\right)$\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X_sr = metatensor.join([co, ps_sr], axis=\"properties\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We used the ``axis=\"properties\"`` parameter since we want to concatenate along the\nfeatures/properties dimensions.\n\nFor the long range model we can formerly write\n\nX_lr: $1 \\oplus \\left(\\rho \\otimes \\rho\\right) \\oplus \\left(\\rho \\otimes\nV\\right)$\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X_lr = metatensor.join([co, ps_sr, ps_lr], axis=\"properties\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The features are now ready! Let us now perform some actual learning. Below we\ninitialize two instances of the :py:class:`equisolve.numpy.models.linear_model.Ridge`\nclass. :py:class:`equisolve.numpy.models.linear_model.Ridge` will perform a regression\nwith respect to ``\"values\"`` (energies) and ``\"positions\"`` gradients (forces).\n\nIf you only want a fit with respect to energies you can remove the gradients with\n``metatensor.remove_gradients()``\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "clf_sr = Ridge()\nclf_lr = Ridge()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Split training and target data into train and test dat\n\nSplit the training and the test data by the distance $r_{\\rm\ntrain}=6\\,\\mathrm{\u00c5}$ between the center of mass of the two molecules. A structure\nwith a $r_{\\rm train}<6 {\\rm \u00c5}$ is used for training.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "r_cut = 6.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We calculate the indices from the dataset by list comprehension. The center of mass\ndistance is stored in the ``\"distance\"\"`` attribute.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "idx_train = [i for i, f in enumerate(frames) if f.info[\"distance\"] < r_cut]\nidx_test = [i for i, f in enumerate(frames) if f.info[\"distance\"] >= r_cut]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For doing the split we define two ``Labels`` instances and combine them in a\n:py:class:`List`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "samples_train = metatensor.Labels([\"structure\"], np.reshape(idx_train, (-1, 1)))\nsamples_test = metatensor.Labels([\"structure\"], np.reshape(idx_test, (-1, 1)))\ngrouped_labels = [samples_train, samples_test]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "That we use as input to the :py:func:`metatensor.split()` function\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X_sr_train, X_sr_test = metatensor.split(\n    X_sr, axis=\"samples\", grouped_labels=grouped_labels\n)\n\nX_lr_train, X_lr_test = metatensor.split(\n    X_lr, axis=\"samples\", grouped_labels=grouped_labels\n)\n\ny_train, y_test = metatensor.split(y, axis=\"samples\", grouped_labels=grouped_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fit the model\n\nFor this model, we use a very simple regularization scheme where all features are\nregularized in the same way (the amount being controlled by the parameter ``alpha``).\nFor more advanced regularization schemes (regularizing energies and forces differently\nand/or the SR and LR parts differently), see further down.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "clf_sr.fit(X_sr_train, y_train, alpha=1e-6)\nclf_lr.fit(X_lr_train, y_train, alpha=1e-6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluation\n\nFor evaluating the model we calculate the RMSEs using the ``score()`` method. With the\n``parameter_key`` parameter we select which RMSE should be calculated.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\n    \"SR: RMSE energies = \"\n    f\"{clf_sr.score(X_sr_test, y_test, parameter_key='values')[0]:.3f} eV\"\n)\nprint(\n    \"SR: RMSE forces = \"\n    f\"{clf_sr.score(X_sr_test, y_test, parameter_key='positions')[0]:.3f} eV/\u00c5\"\n)\n\nprint(\n    \"LR: RMSE energies = \"\n    f\"{clf_lr.score(X_lr_test, y_test, parameter_key='values')[0]:.3f} eV\"\n)\nprint(\n    \"LR: RMSE forces = \"\n    f\"{clf_lr.score(X_lr_test, y_test, parameter_key='positions')[0]:.3f} eV/\u00c5\"\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We find that the RMSE of the energy and the force of the LR model is smaller compared\nto the SR model. From this we conclude that the LR model performs better for the\nselection of the dataset.\n\nWe additionally, can plot of the binding energy as a function of the distance. For the\nplot we select some properties from the dataset\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dist = np.array([f.info[\"distance\"] for f in frames])\nenergies = np.array([f.info[\"energy\"] for f in frames])\nmonomer_energies = np.array([f.info[\"energyA\"] + f.info[\"energyB\"] for f in frames])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and select only the indices corresponding to our test set.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next we calculate the predicted SR and LR ``TensorMaps``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "y_sr_pred = clf_sr.predict(X_sr)\ny_lr_pred = clf_lr.predict(X_lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And, finally perform the plot.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.scatter(\n    dist, y.block().values[:, 0] - monomer_energies, label=\"target data\", color=\"black\"\n)\n\nplt.scatter(\n    dist,\n    y_sr_pred.block().values[:, 0] - monomer_energies,\n    label=\"short range model\",\n    marker=\"x\",\n)\n\nplt.scatter(\n    dist,\n    y_lr_pred.block().values[:, 0] - monomer_energies,\n    label=\"long range model\",\n    marker=\"s\",\n    facecolor=\"None\",\n    edgecolor=\"orange\",\n)\n\nplt.xlabel(\"center of mass distance in \u00c5\")\nplt.ylabel(r\"$E - E_\\mathrm{monomer}$ in eV\")\nplt.axvline(r_cut, c=\"red\", label=r\"$r_\\mathrm{train}$\")\n\nplt.legend()\nplt.tight_layout()\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}